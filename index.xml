<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Axect&#39;s Blog</title>
    <link>https://axect.github.io/</link>
    <description>Recent content on Axect&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>kr</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Mon, 04 Dec 2023 15:38:04 +0900</lastBuildDate>
    <atom:link href="https://axect.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>🤖 Rust와 미분하기 03: 정방향 자동 미분</title>
      <link>https://axect.github.io/posts/007_ad_3/</link>
      <pubDate>Mon, 04 Dec 2023 15:38:04 +0900</pubDate>
      <guid>https://axect.github.io/posts/007_ad_3/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;🔖 Automatic Differentiation Series&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../002_ad_1&#34;&gt;💻 Numerical Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../002_ad_2&#34;&gt;🖊️ Symbolic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../007_ad_3&#34;&gt;🤖 Automatic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;딥러닝을 구현함에 있어서 가장 중요한 요소가 뭘까요?&#xA;물론 많은 학문으로 구성된 딥러닝의 특성상 모든 요소들이 다 중요하지만, 그 중에서도 특히 신경써야하는 요소가 있습니다.&#xA;이를 찾아내기 위해서 다음의 PyTorch 코드를 살펴봅시다.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;net &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sigmoid()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# x = ...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# y = ...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# criterion = ...&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;opt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SGD(net&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parameters(), lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zero_grad()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; criterion(net(x), y)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;opt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;이를 아무런 딥러닝 프레임워크를 쓰지 않고 구현한다고 생각해봅시다.&#xA;일단 엄밀하게 같은 구현은 아니지만 &lt;code&gt;Linear&lt;/code&gt;와 &lt;code&gt;Sigmoid&lt;/code&gt; 함수 자체의 구현은 단순히 행렬곱과 벡터화된 sigmoid 함수를 사용하여 구현할 수 있으므로 &lt;code&gt;net(x)&lt;/code&gt;를 만드는 것은 어렵지 않습니다.&#xA;다음으로 여기선 &lt;code&gt;criterion&lt;/code&gt;이 무엇인지 명시하지는 않았지만 가장 기본적인 &lt;code&gt;MSE&lt;/code&gt;를 사용한다면 이 역시 간단합니다.&#xA;문제는 &lt;code&gt;opt&lt;/code&gt;부터 시작됩니다.&#xA;&lt;code&gt;SGD&lt;/code&gt;를 구현하려면, 어떤 &lt;code&gt;criterion&lt;/code&gt;이나 신경망 구조에서도 gradient 즉, 도함수를 구할 수 있어야 합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://axect.github.io/about/</link>
      <pubDate>Mon, 06 Nov 2023 19:03:00 +0900</pubDate>
      <guid>https://axect.github.io/about/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/Axect&#34;&gt;&lt;strong&gt;김태근 (Axect)&lt;/strong&gt;&lt;/a&gt;을 소개합니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;저는&#34;&gt;저는&lt;/h2&gt;&#xA;&lt;p&gt;수학, 물리학 그리고 프로그래밍을 좋아하는 대학원생입니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;학력&#34;&gt;학력&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;M.S. &amp;amp; Ph.D. Integrated: 연세대학교 대학원 물리학과 (2017 ~ 2025)&lt;/li&gt;&#xA;&lt;li&gt;B.S.: 연세대학교 천문우주학과 (2012 ~ 2017)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;연구분야&#34;&gt;연구분야&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;천체입자물리&lt;/li&gt;&#xA;&lt;li&gt;암흑물질 및 BSM&lt;/li&gt;&#xA;&lt;li&gt;과학계산 및 기계학습&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;학문-및-기술&#34;&gt;학문 및 기술&lt;/h2&gt;&#xA;&lt;h3 id=&#34;수학&#34;&gt;수학&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;함수해석학&lt;/li&gt;&#xA;&lt;li&gt;수치해석학&#xA;&lt;ul&gt;&#xA;&lt;li&gt;유한차분법&lt;/li&gt;&#xA;&lt;li&gt;유한요소법&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;미분기하학&lt;/li&gt;&#xA;&lt;li&gt;위상수학&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;물리학&#34;&gt;물리학&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;천체입자물리학&lt;/li&gt;&#xA;&lt;li&gt;일반상대성이론&lt;/li&gt;&#xA;&lt;li&gt;양자장이론&lt;/li&gt;&#xA;&lt;li&gt;수리물리학&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;기계학습&#34;&gt;기계학습&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;통계적 기계학습&#xA;&lt;ul&gt;&#xA;&lt;li&gt;선형회귀 (LASSO, Ridge)&lt;/li&gt;&#xA;&lt;li&gt;로지스틱 회귀&lt;/li&gt;&#xA;&lt;li&gt;선형분류&lt;/li&gt;&#xA;&lt;li&gt;Kernel Based Methods&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Kernel Smoothing&lt;/li&gt;&#xA;&lt;li&gt;Kernel Density Estimation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;인공신경망&#xA;&lt;ul&gt;&#xA;&lt;li&gt;MLP, CNN, RNN (LSTM, GRU), Transformer, Mamba&lt;/li&gt;&#xA;&lt;li&gt;Operator learning &amp;amp; Nerual ODE&lt;/li&gt;&#xA;&lt;li&gt;Bayesian Neural Network&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;프로그래밍&#34;&gt;프로그래밍&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;주 언어&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Rust, Julia, Python&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;보조 언어&#xA;&lt;ul&gt;&#xA;&lt;li&gt;C/C++, Haskell&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;프레임워크 및 라이브러리&#xA;&lt;ul&gt;&#xA;&lt;li&gt;수치 계산&#xA;&lt;ul&gt;&#xA;&lt;li&gt;peroxide, BLAS, LAPACK, numpy, scipy&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;시각화&#xA;&lt;ul&gt;&#xA;&lt;li&gt;matplotlib, vegas, ggplot2, plotly&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;웹&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Django, Vue, Firebase, Surge, Hugo, Zola&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;머신러닝&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PyTorch, JAX, Optax, Equinox, Wandb, Optuna, Candle, Tensorflow, Norse&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;프로젝트&#34;&gt;프로젝트&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Peroxide&lt;/strong&gt;: Rust 수치 계산 라이브러리 (Maintainer)&lt;/p&gt;</description>
    </item>
    <item>
      <title>📊 Piecewise Rejection Sampling</title>
      <link>https://axect.github.io/posts/006_prs/</link>
      <pubDate>Fri, 18 Nov 2022 17:49:04 +0900</pubDate>
      <guid>https://axect.github.io/posts/006_prs/</guid>
      <description>&lt;figure&gt;&#xA;    &lt;img src=&#34;https://axect.github.io/posts/images/006_01_test_dist.png&#34;&#xA;         alt=&#34;Differential energy spectrum of ALPs from primordial black hole (PBH)${}^{[1]}$&#34;/&gt; &lt;figcaption style=&#34;text-align:center&#34;&gt;&#xA;            &lt;p&gt;Differential energy spectrum of ALPs from primordial black hole (PBH)&lt;a href=&#34;https://axect.github.io/#footnotes&#34;&gt;${}^{[1]}$&lt;/a&gt;&lt;/p&gt;&#xA;        &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;  누군가 위와 같이 정규화 되지 않은 확률밀도함수 그래프를 가져왔다고 가정해봅시다.&#xA;그러고서는 당신에게 이러한 확률분포를 갖는 데이터 10000개를 만들어달라고 부탁한다면, 어떻게 해야할까요?&lt;/p&gt;&#xA;&lt;p&gt;일단, 임의의 확률밀도함수로부터 데이터를 샘플링 하는 방법에 대해 가장 잘 알려진 방법으로는 다음의 2가지가 있습니다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Inverse_transform_sampling&#34;&gt;Inverse Transform Sampling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Rejection_sampling&#34;&gt;Rejection Sampling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Inverse Transform Sampling은 확률밀도함수의 누적분포함수를 구하고, 그 누적분포함수의 역함수를 구한 뒤, 그 역함수를 이용하여 데이터를 생성하는 방법입니다. 이 방법은 효율적이지만, 확률밀도함수가 어떤 형태를 갖느냐에 따라서 구하는 방법이 달라지기 때문에, 지금의 경우처럼 확률밀도함수의 정확한 꼴을 모를 때는 사용하기가 어렵습니다.&lt;a href=&#34;https://axect.github.io/posts/006_prs/#footnotes&#34;&gt;${}^{[2]}$&lt;/a&gt; 그러나, Rejection Sampling은 확률밀도함수가 어떤 형태를 갖느냐에 상관없이 적용할 수 있는데, 따라서 우리는 이 방법으로 시작해보겠습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>💔 Decorrelation &#43; Deep learning = Generalization</title>
      <link>https://axect.github.io/posts/005_decov/</link>
      <pubDate>Sat, 29 Oct 2022 17:39:54 +0900</pubDate>
      <guid>https://axect.github.io/posts/005_decov/</guid>
      <description>&lt;figure&gt;&#xA;    &lt;img src=&#34;https://axect.github.io/posts/images/005_01_paper.png&#34;&#xA;         alt=&#34;arXiv: 1511.06068&#34;/&gt; &lt;figcaption style=&#34;text-align:center&#34;&gt;&#xA;            &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.06068&#34;&gt;arXiv: 1511.06068&lt;/a&gt;&lt;/p&gt;&#xA;        &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;  딥러닝에서 가장 빈번하게 일어나는 문제로 &lt;span style=&#34;background-color: rgba(255, 255, 0, 0.534);&#34;&gt;&#xA;    &lt;b&gt;Overfitting (과적합)&lt;/b&gt;&#xA;&lt;/span&gt;이 있습니다.&#xA;이는 데이터가 많지 않을 때, 학습을 많이 할 수록 잘 발생하는 문제이며 이로 인하여 훈련 데이터셋에 대해서는 성능이 좋더라도 검증 데이터셋이나 실제 데이터셋에 대해서는 성능이 안 나오는 문제가 발생합니다. 이를 해결하기 위하여 사람들은 여러 방법을 고안했는데, 통계학에서는 일찌감치 Ridge나 LASSO와 같은 regularization 방법을 사용하였으며 딥러닝에서도 마찬가지로 weight을 regularize하거나 신경망에 여러 기술을 적용하는 것들을 도입하였습니다. 이러한 기술로는 다음과 같은 방법들이 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>🦀 Rust 1.62.0 업데이트의 신기능 3가지</title>
      <link>https://axect.github.io/posts/004_rust_1.62.0/</link>
      <pubDate>Fri, 01 Jul 2022 11:56:41 +0900</pubDate>
      <guid>https://axect.github.io/posts/004_rust_1.62.0/</guid>
      <description>&lt;figure&gt;&#xA;    &lt;img src=&#34;https://axect.github.io/posts/images/rustacean.svg&#34;&#xA;         alt=&#34;Ferris the crab&#34; width=&#34;2000&#34;/&gt; &lt;figcaption style=&#34;text-align:center&#34;&gt;&#xA;            &lt;p&gt;&lt;a href=&#34;https://rustacean.net/&#34;&gt;Ferris the crab&lt;/a&gt;&lt;/p&gt;&#xA;        &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;  Rust 언어는 2015년 1.0 버전이 출시된 이래로 &lt;span style=&#34;background-color: rgba(255, 255, 0, 0.534);&#34;&gt;&#xA;    &lt;b&gt;Stable, Beta, Nightly&lt;/b&gt;&#xA;&lt;/span&gt; 세가지 채널로 나누어 꾸준히 업데이트 중입니다. 미리 새로운 기능을 써보고 싶은 개발자들은 Beta와 Nightly를 써볼 수 있지만, 라이브러리를 개발하여 배포하거나, 실제 제품을 만들어야 할 때에는 Stable을 선택할 수 밖에 없습니다. 따라서 Stable 채널의 업데이트는 Rust 환경 전반의 업데이트와 같다고 할 수 있고, 새로운 버전이 출시될때마다 Rust 개발자들의 이목이 집중됩니다.&lt;/p&gt;&#xA;&lt;p&gt;업데이트에는 사소한 버그 수정도 있고, Beta와 Nightly에서 사용되었던 기능들의 안정화도 포함될 수 있으며 꼭 언어와 직접적으로 관련이 없더라도 빌드에 사용되는 도구들의 업데이트도 포함될 수 있습니다. 어떤 업데이트는 넓고 잔잔한 호수에 작은 돌멩이 하나를 던진 것과 같은 작은 파문과 같다면, 어떤 업데이트는 사람들이 오랫동안 기다리던 커다란 댐의 수문 개방과 같은 시원함을 주기도 합니다. 그리고 이번 2022년 6월 30일에 발표된 &lt;span style=&#34;background-color: rgba(255, 255, 0, 0.534);&#34;&gt;&#xA;    &lt;b&gt;1.62.0&lt;/b&gt;&#xA;&lt;/span&gt; 업데이트는 명백히 후자였습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>🏫 고등학교 수학으로 이해하는 선형회귀</title>
      <link>https://axect.github.io/posts/003_highschool_linreg/</link>
      <pubDate>Tue, 09 Mar 2021 22:01:39 +0900</pubDate>
      <guid>https://axect.github.io/posts/003_highschool_linreg/</guid>
      <description>&lt;figure&gt;&#xA;    &lt;img src=&#34;https://axect.github.io/posts/images/breakthrough2016.gif&#34;&#xA;         alt=&#34;2016 Breakthrough of the year&#34;/&gt; &lt;figcaption style=&#34;text-align:center&#34;&gt;&#xA;            &lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2ncTCM7t79o&#34;&gt;2016 Breakthrough of the year&lt;/a&gt;&lt;/p&gt;&#xA;        &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&lt;p&gt;  세계에서 가장 유명하고 권위있는 과학저널인 사이언스(Science)에서는 매년 그 해의 가장 성공적이었다고 여겨지는 과학성과를 발표합니다. 2016년 12월 22일에도 &lt;span style=&#34;background-color: rgba(255, 255, 0, 0.534);&#34;&gt;&#xA;    &lt;b&gt;2016 Breakthrough of the year&lt;/b&gt;&#xA;&lt;/span&gt; 를 발표하면서 2016년에 있었던 과학 성과 중 가장 눈여겨봐야 할 10개의 과학성과를 발표했습니다. 순위는 다음과 같습니다.${}^{[1]}$&lt;/p&gt;&#xA;&lt;center&gt;&#xA;&lt;div class=&#34;animated-border-quote&#34;&gt;&#xA;    &lt;blockquote&gt;&#xA;        &lt;p style=&#34;text-align:left&#34;&gt;&lt;strong&gt;1. 중력파 발견&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;2. 외계행성 &amp;lsquo;프록시마b&amp;rsquo; 발견&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;3. 인공지능 &amp;lsquo;알파고&amp;rsquo;와 이세돌 9단의 대결&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;4. 세포 노화 및 회춘 연구&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;5. 유인원의 마음 읽기 능력 연구&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;6. 단백질 구조설계 기술&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;7. 배아줄기세포로 만든 인공난자&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;8. 초기 인류의 확산 경로 연구&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;9. 휴대용 DNA 분석기&lt;/strong&gt;&lt;br&gt;&#xA;&lt;strong&gt;10. 초박막 메타렌즈 기술&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>🖊️ Rust와 미분하기 02: 기호 미분</title>
      <link>https://axect.github.io/posts/002_ad_2/</link>
      <pubDate>Sat, 03 Oct 2020 03:36:49 +0900</pubDate>
      <guid>https://axect.github.io/posts/002_ad_2/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;🔖 Automatic Differentiation Series&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../002_ad_1&#34;&gt;💻 Numerical Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../002_ad_2&#34;&gt;🖊️ Symbolic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../007_ad_3&#34;&gt;🤖 Automatic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;-수치적-미분의-한계&#34;&gt;📉 수치적 미분의 한계&lt;/h2&gt;&#xA;&lt;p&gt;저번 포스트에서 수치적 미분을 여러가지 방법으로 구현하는 것을 다뤄보았는데, 어떠셨나요?&#xA;아마, 코딩에 대한 조금의 지식만 있으면 오히려 고등학교때의 미분보다 훨씬 쉽게 느껴지셨을 겁니다.&#xA;저희가 사용한 것이라고는 그저 도함수의 정의에 따라 함수에 각 구간 값을 대입한 것이 전부였는데, 이를 코드로 나타내면 결국 다음의 코드에 지나지 않습니다.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Python&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;differentiation&lt;/span&gt;(f, x, h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-06&lt;/span&gt;):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (f(x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; h) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; f(x)) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; h&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;나머지는 이를 객체지향적으로 구현하거나, 함수형 프로그래밍으로 구현하거나 제너릭 프로그래밍을 도입하는 등의 구현방법의 차이일 뿐이었습니다. 이렇게 수치적 미분 방법은 굉장히 간단한 구현과 엄청 빠른 계산속도를 가져서 누구나 쉽게 미분을 할 수 있게 해주었습니다만, 오차가 필연적으로 발생하게 되는 단점이 있었습니다. 따라서 오차에 크게 민감하지 않은 문제나, Step 수가 적어서 오차가 크게 쌓이지 않는 미분방정식을 푸는 경우엔 충분하지만, 오차에 민감하거나 Step 수가 많아서 오차가 쌓여 유의미한 차이를 보여주는 미분방정식의 경우엔 큰 문제를 야기할 수 있습니다. 대표적인 예시로 &amp;ldquo;로렌즈의 나비&amp;quot;가 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>🧙 Rust와 미분하기 01: 수치적 미분</title>
      <link>https://axect.github.io/posts/002_ad_1/</link>
      <pubDate>Sun, 24 May 2020 02:44:11 +0900</pubDate>
      <guid>https://axect.github.io/posts/002_ad_1/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;🔖 Automatic Differentiation Series&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../002_ad_1&#34;&gt;💻 Numerical Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../002_ad_2&#34;&gt;🖊️ Symbolic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../007_ad_3&#34;&gt;🤖 Automatic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;미분은 희대의 천재였던 아이작 뉴턴이래로 없어서는 안 될 중요한 개념이 되었습니다.&#xA;문과나 이과 모두 구분없이 고등학교때 적어도 다항함수의 미분법은 배우며 이공계는 거의 모든 학과에서 미분방정식을 다룹니다. 물리학과의 경우는 좀 더 미분 의존도가 심한데, 당장 물리의 시작이라고 할 수 있는 고전역학부터 오일러-라그랑주 방정식(Euler-Lagrange equation)에 의존하며 물리학과의 핵심이라 할 수 있는 전자기학, 양자역학은 거의 모든 수식에 미분이 빠지지 않습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>🐪 가우시안 정복하기 01: 단일변수</title>
      <link>https://axect.github.io/posts/001_gaussian/</link>
      <pubDate>Fri, 22 May 2020 17:00:31 +0900</pubDate>
      <guid>https://axect.github.io/posts/001_gaussian/</guid>
      <description>&lt;p&gt;물리학이나 통계학 등을 하다보면 항상 마주치는 원수 같은 존재가 있습니다. 별로 어렵지는 않은데 마주칠 때마다 헷갈리는 그 존재는 바로 &lt;strong&gt;가우스 적분&lt;/strong&gt;(Gaussian Integral)입니다.&lt;/p&gt;&#xA;&lt;p&gt;$$\int_{-\infty}^\infty e^{-\alpha x^2} dx$$&lt;/p&gt;&#xA;&lt;p&gt;이공계 대학생이라면 1학년 미적분학 시간에 극좌표계(Polar coordinate)를 이용한 이중적분을 다룰 때 나오는 가장 기본문제로 가우스 적분을 기억할겁니다. 그러나 항상 거의 모두가 그렇듯이 시간이 지나면 지날 수록 기억은 풍화되고 거의 망각의 단계에 이르렀을 때에 갑자기 튀어나오는 낯선 형태의 가우스 적분들은 대처하기가 난감합니다.&lt;/p&gt;&#xA;&lt;p&gt;따라서 여기서는 가우스 적분과 가우시안 분포에 대한 아주 기본적인 성질들을 다시 상기시키고 이를 발판삼아 다변수 가우시안(Multivariate Gaussian)과 여러 활용들을 살펴보도록 하겠습니다.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
